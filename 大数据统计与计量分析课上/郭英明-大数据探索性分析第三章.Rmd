---
title: "big3"
author: "gym"
date: "2020/12/29"
output:
  html_document: default
  pdf_document: default
---



# library packages
```{r}
rm(list=ls())
library(AppliedPredictiveModeling)
library(caret)
library(MASS)
library(e1071)
library(randomForest)
data(segmentationOriginal)
head(segmentationOriginal)
```


# set train data and test data
```{r}
seg <- subset(segmentationOriginal, Case == 'Train')
segtest <- subset(segmentationOriginal, Case == 'Test')

dim(seg)#to show the nrow and names of seg
yclass <- seg$Class #extract the column of Class in seg
xseg <- seg[,-(1:3)]#delete the column from col1 to col3
```

# unsupervised filtration
```{r}
#get rid of the variable with a variance of 0
del_col <- nearZeroVar(xseg)
xseg <- xseg[,-del_col]
#dim(xseg)
```

# eliminate variables that are highly correlated with each other
```{r}
statuscolnum <- grep("Status", names(xseg)) #screening dichotomous 
                                            #qualitative variables
xseg1 <- xseg[, -statuscolnum] #temporarily deletes stereotypes variables
                               # to see the relationship of different variables
#dim(xseg1)
xsegstatus <- xseg[, statuscolnum]
correlations <- cor(xseg1)
dim(correlations)
highcor <- findCorrelation(correlations, 0.75) ##eliminate highly correlated variables
length(highcor)
xsegnum <- xseg1[, -highcor] #remove the strongly correlated variables
xsegdata <- cbind(xsegnum, xsegstatus)
```

# function
```{r}
#supervised filtration
#eliminate not sufficiently related to the dependent variable y
#write pScore()-function to see correlation between x and y
pScore <- function(x,y){
  numX <- length(unique(x))
  if(numX > 2){
    out <- t.test(x~y)$p.value
  }
  else{
    out <- fisher.test(factor(x), y)$p.value
  }
  out
}

#write cal()-function to see correlation between x and y
cal <- function(x){numX <- length(unique(x))}
scores <- apply(X <- xsegdata, MARGIN = 2, FUN = pScore, y = yclass)
tail(scores) #show the last rows

#to write pCorrection()-function to adjust p value
pCorrection <- function(score, p0){
  score <- p.adjust(score, "bonferroni")
  keepers <- (score < p0)
  keepers
}
```

```{r}
result1 <- pCorrection(scores, 0.05)
colnames(xsegdata)[result1]
xsegfilted <- xsegdata[, result1]
dim(xsegfilted)
xyfilted <- cbind(xsegfilted, yclass) #chopper colnums

#encapsulation method
#using stepwise regression to establish binomial regression
initial <- glm(yclass~., data = xyfilted, family = binomial)
resultstep <- stepAIC(initial, direction = 'both')
resultstep$call

#using bulid- in to compare
xtrain <- seg[, -c(1:3, 71, 76, 77)]
ytrain <- seg[, 3]
train <- cbind(xtrain, ytrain)
ytest <- segtest[, 3]
xtest <- segtest[, -c(1:3, 71,76, 77)]
test <- cbind(xtest, ytest)
```


# SBF-LDA
```{r}
ldfCtrl <- sbfControl(method = "repeatedcv", repeats = 5, functions = ldaSBF, verbose = F)
t1 <- Sys.time()
ldaFilter <- sbf(xtrain, ytrain, tol = 1.0e-12, sbfControl = ldfCtrl)
t2 <- Sys.time()
t2-t1 #calculate the runnning time
ldaFilter
```

# SBF-RF
```{r}
rffCtrl <- sbfControl(method = "repeatedcv", repeats = 5, functions = rfSBF, verbose = F)
t1 <- Sys.time()
rfFilter <- sbf(xtrain,ytrain, metric = "ROC",sbfControl = rffCtrl)
t2 <- Sys.time()
t2-t1 #calculate the runnning time
rfFilter
```

# RFE-LDA
```{r}
ldrctrl <- rfeControl(method = "repeatedcv", repeats = 5, verbose = F, functions = ldaFuncs)
set.seed(1)
t1 <- Sys.time()
ldaRFE <- rfe(xtrain, ytrain, metric = "ROC", rfeControl = ldrctrl)
t2 <- Sys.time()
t2-t1
ldaRFE
```

# RFE-RF
```{r}
rfrctrl <- rfeControl(method = "repeatedcv", repeats = 5, verbose = F, functions = rfFuncs)
set.seed(100)
t1 <- Sys.time()
rfRFE <- rfe(xtrain, ytrain, metric = "ROC", rfeControl = rfrctrl)
t2 <- Sys.time()
t2-t1
rfRFE
```


